# ğŸŒ GHCN Spark Analysis (DATA420 Assignment 1)

This is my submission for **DATA420 Assignment 1** . 
The project involves distributed data processing and analysis of the **Global Historical Climatology Network (GHCN)** dataset using **Apache Spark**.

---

## ğŸ§  Project Overview

The full workflow is run in a distributed environment using a cloud-based Spark notebook environment provided by James William, with outputs exported for local analysis and visualisation.

---

## ğŸ“ Repository Structure

```bash
ghcn-spark-analysis/
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ environment.yml            # Optional: conda environment
â”‚
â”œâ”€â”€ notebooks/                 # Primary notebooks for each phase
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”œâ”€â”€ 02_schema_and_loading.ipynb
â”‚   â”œâ”€â”€ 03_enrich_stations.ipynb
â”‚   â”œâ”€â”€ 04_station_checks.ipynb
â”‚   â”œâ”€â”€ 05_station_analysis.ipynb
â”‚   â”œâ”€â”€ 06_geospatial_distance.ipynb
â”‚   â”œâ”€â”€ 07_daily_summary.ipynb
â”‚   â””â”€â”€ 08_visualisations.ipynb
â”‚
â”œâ”€â”€ scripts/                   # Helper scripts for schema, joins, visualisations
â”‚   â”œâ”€â”€ load_schemas.py
â”‚   â”œâ”€â”€ enrich_stations.py
â”‚   â””â”€â”€ visualisation_helpers.py
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                   # (Optional) local copy of samples
â”‚   â”œâ”€â”€ processed/             # Spark output for visualisation
â”‚   â””â”€â”€ sample/                # Small mock files for testing locally
â”‚
â”œâ”€â”€ output/
â”‚   â”œâ”€â”€ figures/               # Charts and plots for report
â”‚   â”œâ”€â”€ tables/                # CSV summaries or aggregations
â”‚   â””â”€â”€ results/               # Misc. output files
â”‚
â””â”€â”€ report/
    â”œâ”€â”€ DATA420_Report.pdf
    â””â”€â”€ supplementary_material.zip
