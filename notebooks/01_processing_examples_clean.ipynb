{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12dfbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./00_notebook_with_setup.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9754a82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe2e90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approximate quantiles with different relative errors (note that a relative error of 0.0 gives you the exact quantiles)\n",
    "\n",
    "probabilities = [0.0, 0.25, 0.5, 0.75, 1.0]  # [min, Q1, median, Q3, max]\n",
    "\n",
    "relativeError = 0.1\n",
    "\n",
    "approxQuantiles = data.stat.approxQuantile(\"Salary\", probabilities, relativeError)\n",
    "\n",
    "print([row[\"Salary\"] for row in data.toLocalIterator()])\n",
    "print(\"\")\n",
    "print(approxQuantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56aa5806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can automate this to compare results for different relative errors \n",
    "\n",
    "probabilities = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
    "\n",
    "results = []\n",
    "for relativeError in [1.0, 0.5, 0.1, 0.0]:\n",
    "    approxQuantiles = data.stat.approxQuantile(\"Salary\", probabilities, relativeError)\n",
    "    results.append([relativeError] + approxQuantiles)\n",
    "\n",
    "display(pandas.DataFrame(results, columns=[\"relativeError\"] + probabilities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4eaa443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dangerous alternative to .head()\n",
    "\n",
    "rows = data.collect()\n",
    "\n",
    "print(type(rows))\n",
    "print(\"\")\n",
    "print(len(rows))\n",
    "print(\"\")\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fac13d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A more dangerous alternative to .collect() as the conversion to a pandas dataframe involves copying\n",
    "\n",
    "data_local = data.toPandas()\n",
    "\n",
    "print(type(data_local))\n",
    "print(\"\")\n",
    "print(data_local)\n",
    "print(\"\")\n",
    "display(data_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b40da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A safe and convenient use of .toPandas() after .limit()\n",
    "\n",
    "display(data.limit(5).toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13adb5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A safe way to iterate over rows one by one locally\n",
    "\n",
    "for row in data.toLocalIterator():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3df0a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a function to each row or partition without having to run .collect()\n",
    "\n",
    "def rowSink(row):\n",
    "    print(row)  # write the output to somewhere external e.g. a database or a message queue\n",
    "\n",
    "def partitionSink(rows):\n",
    "    for row in rows:\n",
    "        print(row)  # write the output to somewhere external e.g. a database or a message queue\n",
    "\n",
    "data.foreach(rowSink)\n",
    "data.foreachPartition(partitionSink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7afd816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrameWriter (note that there are multiple ways to write this but the result is the same)\n",
    "\n",
    "data_path = f\"hdfs:///tmp/data/\"\n",
    "\n",
    "data.write.csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8406d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -ls /tmp/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b187986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrameWriter (note that there are multiple ways to write this but the result is the same)\n",
    "\n",
    "data_path = f\"hdfs:///user/{username}/data/\"\n",
    "\n",
    "(\n",
    "    data.write\n",
    "    .format(\"csv\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"compression\", \"gzip\")\n",
    "    .save(data_path)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea840314",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -ls /user/{username}/data/"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
